# Lab 4 Report

For the challenge, I choose to implement a priority-based scheduler.

## Exercise 1

```c
void *
mmio_map_region(physaddr_t pa, size_t size)
{
	static uintptr_t base = MMIOBASE;

	if (base + ROUNDUP(size, PGSIZE) > MMIOLIM)
		panic("Memory-mapped IO region will overflow in mmio_map_region\n");
	boot_map_region(kern_pgdir, base, ROUNDUP(size, PGSIZE), pa, PTE_PCD|PTE_PWT|PTE_W, 0);
	base += ROUNDUP(size, PGSIZE);
	return (void *)(base - ROUNDUP(size, PGSIZE));
}
```

Following the instructions, we can write this function fairly easily. Note that we need to handle potential overflow and round up `size`. Also, as `base` is a static variable, we need to maintain it to prepare for future calls to this function.



## Exercise 2

```c
void
page_init(void)
{
	size_t i;
	page_free_list = NULL;	// This signifies the end of the free page linked list

	// Page 0 is reserved
	pages[0].pp_ref = 1;
	pages[0].pp_link = NULL;

	for (i = 1; i*PGSIZE < MPENTRY_PADDR; i++) {
		pages[i].pp_ref = 0;
		pages[i].pp_link = page_free_list;
		page_free_list = &pages[i];
	}

	// Lab4 - mark the physical page at MPENTRY_PADDR as in use
	for (; i*PGSIZE < MPENTRY_PADDR+PGSIZE; i++) {
		pages[i].pp_ref = 1;
		pages[i].pp_link = NULL;
	}

	for (; i*PGSIZE < IOPHYSMEM; i++) {
		pages[i].pp_ref = 0;
		pages[i].pp_link = page_free_list;
		page_free_list = &pages[i];
	}
	...
}
```

Following the instruction, we mark the page at `MPENTRY_PADDR` as used.



## Question 1

The `MPBOOTPHYS(s)` macro is used to calculate the absolute physical address of the symbol `s`.

This macro serves as a form of manual relocation. At kernel compile-time and link-time, the text and symbols of `kern/mpentry.S` are linked above `KERNBASE`. However, when control is handed to the AP in `kern/mpentry.S`, the processor runs in real mode, unable to access the symbols, which are linked above `KERNBASE`. Thus the `MPBOOTPHYS(s)` macro is needed so that the APs can access the symbols.

If the macro is omitted, the AP would try to access data above `KERNBASE` in real mode, which is impossible.

This macro is not needed for `boot/boot.S` as it was linked and loaded at `0x7C00`, so that the code, running in real mode, can access the symbols, the addresses of which are accessible in real mode.



## Exercise 3

```c
static void
mem_init_mp(void)
{
	for (size_t i = 0; i < NCPU; i++) {
		boot_map_region(kern_pgdir, KSTACKTOP-i*(KSTKSIZE+KSTKGAP)-KSTKSIZE, KSTKSIZE, PADDR(percpu_kstacks[i]), PTE_P|PTE_W, 0);
	}
}
```

For this function, we can use `mem_init` for reference. We should not call `boot_map_region` on the guard pages. This achieves its function. Also, we refer to `percpu_kstacks` for the address of each CPU's kernel stack.



## Exercise 4

```c
void
trap_init_percpu(void)
{
	size_t id = thiscpu->cpu_id;

	// Setup a TSS so that we get the right stack
	// when we trap to the kernel.
	thiscpu->cpu_ts.ts_esp0 = (uintptr_t)percpu_kstacks[id] + KSTKSIZE;
	thiscpu->cpu_ts.ts_ss0 = GD_KD;
	thiscpu->cpu_ts.ts_iomb = sizeof(struct Taskstate);

	// Initialize the TSS slot of the gdt.
	gdt[(GD_TSS0 >> 3) + id] = SEG16(STS_T32A, 
								     (uint32_t) (&(thiscpu->cpu_ts)),
									 sizeof(struct Taskstate) - 1, 
									 0);
	gdt[(GD_TSS0 >> 3) + id].sd_s = 0;

	// Load the TSS selector (like other segment selectors, the
	// bottom three bits are special; we leave them 0)
	ltr(GD_TSS0 + (id << 3));

	// Load the IDT
	lidt(&idt_pd);
	
}
```

Following the instruction, we use `thiscpu->cpu_ts` to replace `ts`, and change the index in the `gdt` to `(GD_TSS0 >> 3) + id`. We set `thiscpu->cpu_ts.ts_esp0` to the stack top of the current CPU's kernel stack.

This code should now work for all CPUs.



## Exercise 5

We simply lock and unlock the big kernel lock in the specified locations:

```c
void
i386_init(void)
{
	...
	// Lab 4 multitasking initialization functions
	pic_init();

	// Acquire the big kernel lock before waking up APs
	// Your code here:

	lock_kernel();

	// Starting non-boot CPUs
	boot_aps();
	...
}
```

```c
void
mp_main(void)
{
	// We are in high EIP now, safe to switch to kern_pgdir 
	lcr3(PADDR(kern_pgdir));
	cprintf("SMP: CPU %d starting\n", cpunum());

	lapic_init();
	env_init_percpu();
	trap_init_percpu();
	xchg(&thiscpu->cpu_status, CPU_STARTED); // tell boot_aps() we're up

	lock_kernel();
	sched_yield();
}
```

```c
void
trap(struct Trapframe *tf)
{
	...
	if ((tf->tf_cs & 3) == 3) {
		// Trapped from user mode.
		// Acquire the big kernel lock before doing any
		// serious kernel work.

		lock_kernel();

		assert(curenv);
		...
  }
  ...
}
```

```c
void
env_run(struct Env *e)
{
	// An env is already present and running, context switch
	if (curenv != NULL && curenv->env_status == ENV_RUNNING) {
		// cprintf("In env_run: an env already running\n");
		curenv->env_status = ENV_RUNNABLE;
	}
	
	curenv = e;
	curenv->env_status = ENV_RUNNING;
	curenv->env_runs++;

	unlock_kernel();
	lcr3(PADDR(curenv->env_pgdir));
	env_pop_tf(&(curenv->env_tf));
}
```



## Question 2

First, let's do a quick review on the calling process of handling an exception/interrupt. The hardware detects the event, pushes parts of context to stack, and vectors to the corresponding handler, which pushes the remaining parts of the context. The handler then calls `trap`, which acquires the big kernel lock. We note that the process of pushing the context onto the frame is not protected by the big kernel lock.

Thus we can consider this scenario: CPU 0 encounters an event and handles it. Just after it pushes the context onto the shared kernel stack and before it acquires the lock, control is handed to CPU 1, which also encounters an event and pushes the context on the the shared kernel stack. At this point, control is handed back to CPU 0, which acquires the lock and handles the event. When it's done, it pops the context frame pushed by CPU 1, causing a problem.



## Exercise 6

```c
void
sched_yield(void)
{
	size_t envx, cur_envx;

	if (curenv == NULL) {
 		for (size_t envx = 0; envx < NENV; envx++)
	 		if (envs[envx].env_status == ENV_RUNNABLE)
	 			env_run(&envs[envx]);
    
	} else {
	 	size_t cur_envx = ENVX(curenv->env_id);
		size_t envx;

	 	if (cur_envx == NENV-1)		envx = 0;
	 	else						envx = cur_envx+1;

	 	for (; envx != cur_envx;) {
	 		if (envs[envx].env_status == ENV_RUNNABLE)
	 			env_run(&(envs[envx]));

      if (envx == NENV-1)		envx = 0;
      else					envx++;
    }
	}

	if (envs[cur_envx].env_status == ENV_RUNNING)
	 	env_run(&(envs[cur_envx]));
	}

	// sched_halt never returns
 	sched_halt();
}
```

In this function, we iterate though all possible environments starting from the current environment (or the first one if no environment is currently running) until we find the first runnable environment, or the original environment, if it's still running.

Then we add `sched_yield()` to all syscalls:

```c
int32_t
syscall(uint32_t syscallno, uint32_t a1, uint32_t a2, uint32_t a3, uint32_t a4, uint32_t a5)
{
	switch (syscallno) {
		...
		case SYS_yield:
			sys_yield();
			return 0;
		...
	}
}
```



## Question 3

All environment switches happen as a result of `sched_yield()`, in which an entry in `envs` is passed to `env_run()`. `envs` is mapped to `UENVS` in the kernel page directory in `mem_init()`; and after this, when each environment is created, the kernel page directory is copied over to be used as the initial user environment page directory. As a result, the kernel and all user environment page directory share the same mapping for `envs`, and thus `e` refers to the same data structure no matter which page directory is in effect.



## Question 4

If the old registers are not saved, then when we return to the old environment, the registers might be altered, which would lead to faulty results or crashes. 

When `sys_yield()` is called, it will, at some point in the process, be detected by the trap handler and have the context pushed onto the stack. This is how the registers are saved.



## Exercise 7

For this exercise, we should keep in mind to perform checking for any operation during which errors may occur. 

For `sys_exofork()`, we need to set the return value of the child process to 0. We do this by setting the `eax` register in the child's trap frame:

```c
static envid_t
sys_exofork(void)
{
	// Allocate new environment
	struct Env *env_store;

	int env_alloc_status = env_alloc(&env_store, curenv->env_id);
	if (env_alloc_status < 0)
		return env_alloc_status;

	env_store->env_tf = curenv->env_tf;
	env_store->env_status = ENV_NOT_RUNNABLE;
	env_store->env_tf.tf_regs.reg_eax = 0;
	
	return env_store->env_id;
}
```

And for `sys_env_set_status()`, we also need to carry out plenty of argument checking:

```c
static int
sys_env_set_status(envid_t envid, int status)
{
	struct Env *env_store;

	int envid2env_status = envid2env(envid, &env_store, 1);
	if (envid2env_status)
		return envid2env_status;

	if (status != ENV_RUNNABLE && status != ENV_NOT_RUNNABLE)
		return -E_INVAL;

	env_store->env_status = status;

	return 0;
}
```

For `sys_page_alloc()`, we allocate a page and insert it in the specified environment's specified virtual address. I find it easier to organize the function by carrying out the checks specified in the comments one by one:

```c
static int
sys_page_alloc(envid_t envid, void *va, int perm)
{
	// Check envid
	struct Env *env_store;
	
	int envid2env_status = envid2env(envid, &env_store, 1);
	if (envid2env_status)
		return envid2env_status;

	// Check va
	if ((uintptr_t)va >= UTOP || (uintptr_t)va % PGSIZE)
		return -E_INVAL;

	// Check perm
	if (!((perm & PTE_U) && (perm & PTE_P) && !(perm & (~PTE_SYSCALL))))
		return -E_INVAL;
  
	struct PageInfo *pp = page_alloc(ALLOC_ZERO);
	if (pp == NULL)
		return -E_NO_MEM;

	int page_insert_status = page_insert(env_store->env_pgdir, pp, va, perm);
	if (page_insert_status) {
		page_free(pp);
		return page_insert_status;
	}

	return 0;
}
```

Still lots of checking for `sys_page_map()`:

```c
static int
sys_page_map(envid_t srcenvid, void *srcva,
	     envid_t dstenvid, void *dstva, int perm)
{
	// Check for error 1
	struct Env *srcenv;
	struct Env *dstenv;

	int srcenv_stat = envid2env(srcenvid, &srcenv, 1);
	if (srcenv_stat)
		return srcenv_stat;
	int dstenv_stat = envid2env(dstenvid, &dstenv, 1);
	if (dstenv_stat)
		return dstenv_stat;

	// Check for error 2
	uintptr_t srcptr = (uintptr_t)srcva;
	uintptr_t dstptr = (uintptr_t)dstva;

	if ((srcptr >= UTOP) || (dstptr >= UTOP) || (srcptr % PGSIZE) || (dstptr % PGSIZE))
		return -E_INVAL;

	// Check for error 4
	if (!((perm & PTE_U) && (perm & PTE_P) && !(perm & (~PTE_SYSCALL))))
		return -E_INVAL;

	// Get the page mapped in source
	pte_t *pte;
	struct PageInfo *srcpp = page_lookup(srcenv->env_pgdir, srcva, &pte);
	if (srcpp == NULL)
		return -E_INVAL;	// Check for error 3
	if ((perm & PTE_W) && !((*pte) & PTE_W))
		return -E_INVAL;	// Check for error 5

	int page_insert_stat = page_insert(dstenv->env_pgdir, srcpp, dstva, perm);
	if (page_insert_stat)
		return page_insert_stat;	// Check for error 6

	return 0;
}
```

And `sys_page_unmap()` is a wrapper around `page_remove()`:

```c
static int
sys_page_unmap(envid_t envid, void *va)
{
	// Check for error 1
	struct Env *env_store;
	
	int envid2env_status = envid2env(envid, &env_store, 1);
	if (envid2env_status)
		return envid2env_status;

	// Check for error 2
	if (((uintptr_t)va >= UTOP) || ((uintptr_t)va % PGSIZE))
		return -E_INVAL;

	page_remove(env_store->env_pgdir, va);

	return 0;
}
```

And we make them dispatchable by `syscall()`:

```c
int32_t
syscall(uint32_t syscallno, uint32_t a1, uint32_t a2, uint32_t a3, uint32_t a4, uint32_t a5)
{
	switch (syscallno) {
		...
		case SYS_exofork:
			return sys_exofork();
		case SYS_env_set_status:
			return sys_env_set_status((envid_t)a1, (int)a2);
		case SYS_page_alloc:
			return sys_page_alloc((envid_t)a1, (void *)a2, (int)a3);
		case SYS_page_map:
			return sys_page_map((envid_t)a1, (void *)a2, (envid_t)a3, (void *)a4, (int)a5);
		case SYS_page_unmap:
			return sys_page_unmap((envid_t)a1, (void *)a2);
		...
	}
}
```



## Exercise 8

For `sys_env_set_pgfault_upcall`, we simply perform argument checking and set one of `struct Env`'s fields:

```c
static int
sys_env_set_pgfault_upcall(envid_t envid, void *func)
{
	struct Env *env_store;

	int envid2env_status = envid2env(envid, &env_store, 1);
	if (envid2env_status)
		return envid2env_status;

	env_store->env_pgfault_upcall = func;

	return 0;
}
```

For `page_fault_handler`, we need to do the following things:

1. Test if `curenv->env_pgfault_upcall` is provided. If not, destroy the environment.
2. Determine the location for the new user trap frame for two possible cases: the previous frame is on the normal user stack or user exception stack.
3. Check if the location for the user trap frame is viable with `user_mem_assert()`.
4. Set up the user trap frame with values from the trap frame and `fault_va`.
5. Set up the starting point by changing the `tf_eip` field in `tf` (note that when we run the user level page fault handler with `env_run(curenv)` later, it uses the system trap frame for restoring context), and set up the user trap frame by setting the `tf_esp` field in `tf` to the location of the user trap frame.
6. Use `env_run(curenv)` to pass control to the user page fault handler.

```c
void
page_fault_handler(struct Trapframe *tf)
{
	uint32_t fault_va;

	// Read processor's CR2 register to find the faulting address
	fault_va = rcr2();

	// Handle kernel-mode page faults.
	// LAB 3: Your code here.

	if (tf->tf_cs == GD_KT)
		panic("page fault in kernel\n");

	// LAB 4: Your code here.

	// Test if upcall func is provided
	if (curenv->env_pgfault_upcall == 0)
		goto no_upcall;

	// Calculate location for user trap frame
	struct UTrapframe *utf;
	// Already using exception stack
	if ((tf->tf_esp >= UXSTACKTOP-PGSIZE) && (tf->tf_esp < UXSTACKTOP)) {	
        *(uint32_t *)(tf->tf_esp - 4) = 0;
        utf = (struct UTrapframe *)(tf->tf_esp - 4 - sizeof(struct UTrapframe));
    } 
	// Coming from normal stack
	else
        utf = (struct UTrapframe *)(UXSTACKTOP - sizeof(struct UTrapframe));
	
	// Test whether the environment didn't allocate a page for its exception stack,
	// can't write to it, 
	// or the exception stack overflows
	user_mem_assert(curenv, (void *)utf, sizeof(struct UTrapframe), PTE_W);
 
	// Set up utf, which is only used to return to the context
	utf->utf_fault_va = fault_va;
	utf->utf_err 	  = tf->tf_err;
	utf->utf_regs     = tf->tf_regs;
	utf->utf_eip      = tf->tf_eip;
	utf->utf_eflags   = tf->tf_eflags;
	utf->utf_esp      = tf->tf_esp;

	// Set up tf to set up starting point, as we will be using env_run
	tf->tf_eip = (uint32_t)curenv->env_pgfault_upcall;
	tf->tf_esp = (uint32_t)utf;

	// Run the user-level page fault handler
	env_run(curenv);

	// Destroy the environment that caused the fault.
	no_upcall: cprintf("[%08x] user fault va %08x ip %08x\n",
		curenv->env_id, fault_va, tf->tf_eip);
	print_trapframe(tf);
	env_destroy(curenv);
}
```

As for protection for the user exception stack, when the user environment runs out of space on the exception stack, it goes into the memory region below the exception stack, which is empty memory. `user_mem_assert` would notice this issue and destroy the environment.



## Exercise 10

The goal of the assembly code is to return to the trap-time state defined by the user trap frame. We can restore the registers in the user trap frame with `popal`. And while it seems simple to put the utf's `eip` field into the `eip` register, note that this step comes after restoring the registers, at which time we cannot modify the registers anymore, thus we cannot use them as intermediaries.

This leaves us with the option of using the `ret` instruction. But if we pop the trap-time `eip` straight from its field in the utf, the program jumps to the address specified by the `eip`'s value, and we still have stuff to do after that!

This is where the scratch space we've reserved comes into play. By storing the trap-time `eip` in the scratch space below the previous stack frame beforehand, we can `ret` as the last thing in our code, after we have used `esp` to go to the previous stack frame. As a result of this, to "enlarge" the previous stack frame by 4 bytes, we subtract 4 from the current utf's `esp` field.

To conclude, we need to:

1. Put the current utf's `eip` in the scratch space below the previous stack frame.
2. Subtract 4 from the current utf's `esp`.
3. Restore the necessary registers from the current utf.
4. Set the `esp` to the bottom of the enlarged previous stack frame.
5. Call `ret` to go to the trap-time instruction address.

Putting them together:

```assembly
_pgfault_upcall:
	// Call the C page fault handler.
	pushl %esp			// function argument: pointer to UTF
	movl _pgfault_handler, %eax
	call *%eax
	addl $4, %esp			// pop function argument
	
	// Now the C page fault handler has returned and you must return
	// to the trap time state.
	// Push trap-time %eip onto the trap-time stack.
	movl 0x30(%esp), %edi	// Move the trap-time esp to an intermediate register
	subl $4, %edi			// Subtract 4 from trap-time esp, effectively enlarging the previous frame
	movl %edi, 0x30(%esp)	// Move (trap-time esp-4) to esp slot in current user trap frame

	movl 0x28(%esp), %esi	// Move trap-time eip to (trap-time esp - 4) with intermediary
	movl %esi, (%edi)

	// Restore the trap-time registers.  After you do this, you
	// can no longer modify any general-purpose registers.
	addl $8, %esp	// Skip utf_fault_va and utf_err
	popal			// Restore utf_regs

	// Restore eflags from the stack.  After you do this, you can
	// no longer use arithmetic operations or anything else that
	// modifies eflags.
	addl $4, %esp	// Skip utf_eip
	popfl			// Resume flags

	// Switch back to the adjusted trap-time stack.
	popl %esp	// Pop off trap-time esp - 4. This is now the locatio of the stack. As they are both user-space, a simple pop is enough

	// Return to re-execute the instruction that faulted.
	ret

```



## Exercise 11

If it's the first time we are calling the function, we also need to allocate a page for the current environment's exception stack, and set its page fault upcall:

```c
void
set_pgfault_handler(void (*handler)(struct UTrapframe *utf))
{
	int r;

	if (_pgfault_handler == 0) {
		// First time through!
		if ((r = sys_page_alloc(thisenv->env_id, (void *)(UXSTACKTOP-PGSIZE), PTE_U|PTE_W|PTE_P)))
			panic("In sys_page_alloc in set_pgfault_handler: %e\n", r);

		if ((r = sys_env_set_pgfault_upcall(thisenv->env_id, _pgfault_upcall)))
			panic("In sys_env_set_pgfault_upcall in set_pgfault_handler: %e\n", r);
	}

	// Save handler pointer for assembly to call.
	_pgfault_handler = handler;
}
```



## Exercise 12

According to the instructions, we need to do 5 things. The others are fairly straightforward, so we will focus on setting up the child process's page mapping below the exception stack.

Firstly, let's do a quick recap on `uvpt` and `uvpd`. In short, both of their page directory index fields are set up so that after a query into the page directory, the `pte` they land back on is still the page directory. And `uvpt`'s page table index field is same up the same way, so that a second query into the page directory still lands back on the page directory. Thus, we can use `uvpd[PDX(va)]` to access `va`'s page table's entry, and use `uvpt[PGNUM(va)]` to access the page's entry.

If `va`'s page table and page are both present (do not refer to anything about the page entry until we've checked whether the page table's entry is present!), we can check if it's writable or copy-on-write. If so, we map it COW with `duppage()`. Otherwise, as it's read-only, we simply copy the mapping over.

```c
envid_t
fork(void)
{
	envid_t chld_envid;
	pte_t pte;
	int r;

	// Install pgfault() as C-level page fault handler
	set_pgfault_handler(pgfault);

	// Create children
	if ((chld_envid = sys_exofork()) > 0) {	// In parent
		envid_t prnt_envid = sys_getenvid();

		// Everything below exception stack
		for (uintptr_t va = 0; va < USTACKTOP; va += PGSIZE) {

			if (uvpd[PDX(va)] & PTE_P)	// Page table is present
				pte = uvpt[PGNUM(va)];
			else
				continue;

			if (pte & PTE_P) {		// Page is present
				if ((pte & PTE_W) || (pte & PTE_COW)) {	// Writable or copy-on-write, call duppage
					if ((r = duppage(chld_envid, PGNUM(va)))) return r;
				} else {	// Read-only pages, suffice to copy mapping
					if ((r = sys_page_map(prnt_envid, (void *)va, chld_envid, (void *)va, PTE_P|PTE_U))) return r;
				}
			}
		}

		// Duplicate exception stack
		if ((r = sys_page_alloc(chld_envid, (void *)(UXSTACKTOP-PGSIZE), PTE_P|PTE_U|PTE_W))) return r;

		// Set child's page fault entry point (upcall)
		if ((r = sys_env_set_pgfault_upcall(chld_envid, thisenv->env_pgfault_upcall))) return r;

		// Mark child as runnable
		if ((r = sys_env_set_status(chld_envid, ENV_RUNNABLE))) return r;

		return chld_envid;

	} else if (chld_envid == 0) {			// In child
		// Fix "thisenv" in the child process
		thisenv = &envs[ENVX(sys_getenvid())];

		return 0;

	} else							// Error
		return chld_envid;
}
```
We implement `duppage()` as a wrapper to two calls to `sys_page_map()`. Note that we need to map the page to the child first before we map it to itself.

```c
static int
duppage(envid_t envid, unsigned pn)
{
	int r;
	envid_t prnt_envid = sys_getenvid();

	uintptr_t va = pn << PTXSHIFT;

	if ((r = sys_page_map(prnt_envid, (void *)va, envid, (void *)va, PTE_P|PTE_U|PTE_COW))) return r;
	if ((r = sys_page_map(prnt_envid, (void *)va, prnt_envid, (void *)va, PTE_P|PTE_U|PTE_COW))) return r;
	
	return 0;
}
```
For `pgfault()`, after checking if the faulting address is COW and if the faulting access is a write, we need to allocate a new page at the temporary location with `sys_page_alloc()`, copy the page including `addr`'s content over with `mem_cpy()`, map the temporary page back to `addr`'s page with `sys_page_map()`, and unmap the temporary page with `sys_page_unmap()` (this is not necessary, but no harm). One thing to keep in mind is to round down `addr` to its corresponding page boundary, as `memcpy` and `sys_page_map()` do not enforce checks on this.
```c
static void
pgfault(struct UTrapframe *utf)
{
	void *addr = (void *) utf->utf_fault_va;
	uint32_t err = utf->utf_err;
	int r;

	uintptr_t int_addr = (uintptr_t)addr;

	if (!(uvpd[PDX(int_addr)] & PTE_P))
		panic("Page table not present");
	if (!(uvpt[PGNUM(int_addr)] & PTE_P))
		panic("Page not present");
	if (!(uvpt[PGNUM(int_addr)] & PTE_COW))
		panic("Page not COW");
	if (!(err & FEC_WR))
		panic("Faulting access not write");

	envid_t envid = sys_getenvid();

	if ((r = sys_page_alloc(envid, PFTEMP, PTE_P|PTE_U|PTE_W)))
		panic("In sys_page_alloc in lib/fork.c:pgfault: %e", r);

	if (memcpy(PFTEMP, ROUNDDOWN(addr, PGSIZE), PGSIZE) == NULL)
		panic("In lib/fork.c:pgfault: memcpy fails");

	if ((r = sys_page_map(envid, PFTEMP, envid, ROUNDDOWN(addr, PGSIZE), PTE_P|PTE_U|PTE_W)))
		panic("In sys_page_map in lib/fork.c:pgfault: %e", r);

	if ((r = sys_page_unmap(envid, PFTEMP)))
        panic("In sys_page_unmap in lib/fork.c:pgfault: %e", r);
}
```

## Exercise 13

Much like what we did for traps, declare the handlers in `trapentry.S`, which all do not push an error code.

```assembly
...
TRAPHANDLER_NOEC(irq0_hdlr, 32)
TRAPHANDLER_NOEC(irq1_hdlr, 33)
TRAPHANDLER_NOEC(irq2_hdlr, 34)
TRAPHANDLER_NOEC(irq3_hdlr, 35)
TRAPHANDLER_NOEC(irq4_hdlr, 36)
TRAPHANDLER_NOEC(irq5_hdlr, 37)
TRAPHANDLER_NOEC(irq6_hdlr, 38)
TRAPHANDLER_NOEC(irq7_hdlr, 39)
TRAPHANDLER_NOEC(irq8_hdlr, 40)
TRAPHANDLER_NOEC(irq9_hdlr, 41)
TRAPHANDLER_NOEC(irq10_hdlr, 42)
TRAPHANDLER_NOEC(irq11_hdlr, 43)
TRAPHANDLER_NOEC(irq12_hdlr, 44)
TRAPHANDLER_NOEC(irq13_hdlr, 45)
TRAPHANDLER_NOEC(irq14_hdlr, 46)
TRAPHANDLER_NOEC(irq15_hdlr, 47)
...
```

And install them in `trap_init()`:

```c

void
trap_init(void)
{
  ...
  void irq0_hdlr();
  void irq1_hdlr();
  void irq2_hdlr();
  void irq3_hdlr();
  void irq4_hdlr();
  void irq5_hdlr();
  void irq6_hdlr();
  void irq7_hdlr();
  void irq8_hdlr();
  void irq9_hdlr();
  void irq10_hdlr();
  void irq11_hdlr();
  void irq12_hdlr();
  void irq13_hdlr();
  void irq14_hdlr();
  void irq15_hdlr();
  ...
  SETGATE(idt[IRQ_OFFSET+0], 0, GD_KT, &irq0_hdlr, 0);
	SETGATE(idt[IRQ_OFFSET+1], 0, GD_KT, &irq1_hdlr, 0);
	SETGATE(idt[IRQ_OFFSET+2], 0, GD_KT, &irq2_hdlr, 0);
	SETGATE(idt[IRQ_OFFSET+3], 0, GD_KT, &irq3_hdlr, 0);
	SETGATE(idt[IRQ_OFFSET+4], 0, GD_KT, &irq4_hdlr, 0);
	SETGATE(idt[IRQ_OFFSET+5], 0, GD_KT, &irq5_hdlr, 0);
	SETGATE(idt[IRQ_OFFSET+6], 0, GD_KT, &irq6_hdlr, 0);
	SETGATE(idt[IRQ_OFFSET+7], 0, GD_KT, &irq7_hdlr, 0);
	SETGATE(idt[IRQ_OFFSET+8], 0, GD_KT, &irq8_hdlr, 0);
	SETGATE(idt[IRQ_OFFSET+9], 0, GD_KT, &irq9_hdlr, 0);
	SETGATE(idt[IRQ_OFFSET+10], 0, GD_KT, &irq10_hdlr, 0);
	SETGATE(idt[IRQ_OFFSET+11], 0, GD_KT, &irq11_hdlr, 0);
	SETGATE(idt[IRQ_OFFSET+12], 0, GD_KT, &irq12_hdlr, 0);
	SETGATE(idt[IRQ_OFFSET+13], 0, GD_KT, &irq13_hdlr, 0);
	SETGATE(idt[IRQ_OFFSET+14], 0, GD_KT, &irq14_hdlr, 0);
	SETGATE(idt[IRQ_OFFSET+15], 0, GD_KT, &irq15_hdlr, 0);
	...
}
```

Following the instructions, we add this line in `env_alloc()` to enable external interrupts in each environment:

```c
int
env_alloc(struct Env **newenv_store, envid_t parent_id)
{
	...
	e->env_tf.tf_cs = GD_UT | 3;
	// You will set e->env_tf.tf_eip later.

	// Enable interrupts while in user mode.
	e->env_tf.tf_eflags |= FL_IF;

	// Clear the page fault handler until user installs one.
	e->env_pgfault_upcall = 0;

	...
}
```



## Exercise 14

We add a case to `trap_dispatch()`, calling `lapic_eoi()` before `sched_yield()` as the comment says:

```c
static void
trap_dispatch(struct Trapframe *tf)
{
	switch (tf->tf_trapno) {
		...
		case IRQ_OFFSET+IRQ_TIMER:
			// Handle clock interrupts. Don't forget to acknowledge the
			// interrupt using lapic_eoi() before calling the scheduler!
			lapic_eoi();
			sched_yield();
			return;
	}		
	...
}
```



## Exercise 15

For `sys_ipc_try_send()`, we carry out the checks one by one. After we've passed all tests, we set fields of the environment to send a value and optional a page.

```c
static int
sys_ipc_try_send(envid_t envid, uint32_t value, void *srcva, unsigned perm)
{
	// LAB 4: Your code here.
	// TODO - Done

	struct Env *recv_env;
	int r;

	if ((r = envid2env(envid, &recv_env, 0))) return r;	// Check 1

	if (!(recv_env->env_ipc_recving)) return -E_IPC_NOT_RECV;	// Check 2

	if (((uintptr_t)srcva < UTOP) && ((uintptr_t)(recv_env->env_ipc_dstva) < UTOP)) {	// Send a page mapping
		if (PGOFF(srcva)) return -E_INVAL;	// Check 3

		if (!((perm & PTE_U) && (perm & PTE_P) && !(perm & (~PTE_SYSCALL)))) return -E_INVAL; // Check 4
		
		pte_t *pte;
		struct PageInfo *pp = page_lookup(curenv->env_pgdir, srcva, &pte);
		if (pp == NULL) return -E_INVAL;	// Check 5

		if ((perm & PTE_W) && !((*pte) & PTE_W)) return -E_INVAL;	// Check 6

		if ((r = page_insert(recv_env->env_pgdir, pp, recv_env->env_ipc_dstva, perm))) return r; // Check 7

		recv_env->env_ipc_perm = perm;
	} else
		recv_env->env_ipc_perm = 0;

	recv_env->env_ipc_recving = 0;
	recv_env->env_ipc_from = curenv->env_id;
	recv_env->env_ipc_value = value;
	recv_env->env_status = ENV_RUNNABLE;

	return 0;
}
```

For `sys_ipc_recv()`, we set fields of the current environment to mark it as ready to receive and blocked. Note that although the comments say that this function should not return 0 on success explicitly but give up the CPU, if we do so with `sched_yield()`, the function returns a non-zero value and fails the check.

```c
static int
sys_ipc_recv(void *dstva)
{
	// LAB 4: Your code here.
	// TODO - WIP

	if (((uintptr_t)dstva < UTOP) && PGOFF(dstva)) return -E_INVAL;

	curenv->env_ipc_recving = 1;
	curenv->env_ipc_dstva = dstva;
	curenv->env_status = ENV_NOT_RUNNABLE;

	return 0;
}
```

Then we add the kernel dispatchers:

```c
int32_t
syscall(uint32_t syscallno, uint32_t a1, uint32_t a2, uint32_t a3, uint32_t a4, uint32_t a5)
{
	switch (syscallno) {
		...
		case SYS_ipc_recv:
    		return sys_ipc_recv((void *)a1);
		case SYS_ipc_try_send:
    		return sys_ipc_try_send((envid_t)a1, (uint32_t)a2, (void *)a3, (unsigned int)a4);
		...
	}
}
```

And their system call numbers in `syscall.h`:

```c
enum {
	SYS_cputs = 0,
	SYS_cgetc,
	SYS_getenvid,
	SYS_env_destroy,
	SYS_page_alloc,
	SYS_page_map,
	SYS_page_unmap,
	SYS_exofork,
	SYS_env_set_status,
	SYS_env_set_pgfault_upcall,
	SYS_yield,
	SYS_ipc_try_send,
	SYS_ipc_recv,
	SYS_env_set_priority,	// Lab 4 challenge: priority scheduling
	NSYSCALLS
};
```

And the user-level system calls:

```c
int
sys_ipc_try_send(envid_t envid, uint32_t value, void *srcva, int perm)
{
	return syscall(SYS_ipc_try_send, 0, envid, value, (uint32_t) srcva, perm, 0);
}

int
sys_ipc_recv(void *dstva)
{
	return syscall(SYS_ipc_recv, 1, (uint32_t)dstva, 0, 0, 0, 0);
}
```

And the wrapper functions. For `ipc_send()`, we set `pg` to `UTOP`(indicating invalid) if it's `NULL`, and loop calling `sys_ipc_try_send()` until it gets through, using `sys_yield()` to free up the CPU.

```c
void
ipc_send(envid_t to_env, uint32_t val, void *pg, int perm)
{
	int r;

	if (pg == NULL)
		pg = (void *)UTOP;
	
	do {
		r = sys_ipc_try_send(to_env, val, pg, perm);
		if ((r != 0) && r != (-E_IPC_NOT_RECV))
			panic("In sys_ipc_try_send in ipc_send: %e", r);
		sys_yield();
	} while (r);
}
```

And as for `ipc_recv()`, we mostly need to do error handling.

```c
int32_t
ipc_recv(envid_t *from_env_store, void *pg, int *perm_store)
{
	int r;

	if (pg == NULL)
		pg = (void *)UTOP;

	if ((r = sys_ipc_recv(pg)) < 0) {
		if (from_env_store) *from_env_store = 0;
		if (perm_store) *perm_store = 0;
		return r;
	}

	if (from_env_store) *from_env_store = thisenv->env_ipc_from;
	if (perm_store) *perm_store = thisenv->env_ipc_perm;

	return thisenv->env_ipc_value;
}
```

Now, we can pass every case in `make grade`.

## Challenge

For the challenge, I chose to implement a priority-based scheduler. I break it down into the following parts:

1. Add a field to `struct Env` to record the priority

```c
struct Env {
	...
	// Lab 4 priority scheduling challenge
	uint8_t env_priority;	// Priority of environment, lower means higher priority
};
```

2. Initialize this field for each environment's init phase

```c
int
env_alloc(struct Env **newenv_store, envid_t parent_id)
{
	...
	e->env_runs = 0;

	// Lab 4 challenge: also set up priority
	e->env_priority = 100;

	// Clear out all the saved register state,
	// to prevent the register values
	// of a prior environment inhabiting this Env structure
	// from "leaking" into our new environment.
	memset(&e->env_tf, 0, sizeof(e->env_tf));
	...
}
```

3. Implement syscalls for changing an environment's priority. Note that we does not check whether the calling environment has the permission to change the target environment's priority. Be nice!

```c
static int
sys_env_set_priority(envid_t envid, uint8_t priority)
{
	struct Env *env;
	int r;
	
	if ((r = envid2env(envid, &env, 0))) return r;

	env->env_priority = priority;

	return 0;
}
```

```c
int32_t
syscall(uint32_t syscallno, uint32_t a1, uint32_t a2, uint32_t a3, uint32_t a4, uint32_t a5)
{
	switch (syscallno) {
		...
		case SYS_env_set_priority:	// Lab 4 challenge: priority scheduling
			return sys_env_set_priority((envid_t)a1, (uint8_t)a2);
		...
	}
}
```

```c
enum {
	SYS_cputs = 0,
	SYS_cgetc,
	SYS_getenvid,
	SYS_env_destroy,
	SYS_page_alloc,
	SYS_page_map,
	SYS_page_unmap,
	SYS_exofork,
	SYS_env_set_status,
	SYS_env_set_pgfault_upcall,
	SYS_yield,
	SYS_ipc_try_send,
	SYS_ipc_recv,
	SYS_env_set_priority,	// Lab 4 challenge: priority scheduling
	NSYSCALLS
};
```

```c
int
sys_env_set_priority(envid_t envid, uint8_t priority) {
	return syscall(SYS_env_set_priority, 1, (uint32_t)envid, (uint32_t)priority, 0, 0, 0);
}
```

4. Finally, we modify the `sched_yield()` function to take into account priority. The goal is to choose the environment with the highest priority that is also closest to the current environment. It can be implemented like this:

```c
void
sched_yield(void)
{
	size_t envx, cur_envx, best_choice = 0;
	uint8_t min_priority = __UINT8_MAX__;

	if (curenv == NULL) {	// Starting from kernel
		for (envx = 0; envx < NENV; envx++) {
			if (envs[envx].env_status == ENV_RUNNABLE && envs[envx].env_priority < min_priority) {
				min_priority = envs[envx].env_priority;
				best_choice = envx;
			}
		}

		if (min_priority == __UINT8_MAX__)
			sched_halt();

		env_run(&envs[best_choice]);

	} else {	// Starting from another env
		cur_envx = ENVX(curenv->env_id);
		envx = (cur_envx+1) % NENV;

		while (envx != cur_envx) {
			if (envs[envx].env_status == ENV_RUNNABLE && envs[envx].env_priority < min_priority) {
				min_priority = envs[envx].env_priority;
				best_choice = envx;
			}
			envx = (envx+1) % NENV;
		}

		if (min_priority == __UINT8_MAX__) {	// No runnable envs
			if (envs[cur_envx].env_status == ENV_RUNNING)
	 			env_run(&(envs[cur_envx]));
			else
				sched_halt();
		}

		env_run(&envs[best_choice]);
	}

	sched_halt();
}
```

5. Additionally, we write a user program to test the correctness of the code. `user/nice.c`contains:

```c
// Lab 4 challenge: priority scheduling
// Check if we've implemented priority scheduling correctly!
// umain forks off 5 children with priority 0 through 2. 
// They should run in this order!

#include <inc/lib.h>

void
umain(int argc, char **argv)
{	
	
	envid_t chld0, chld1, chld2;
	int r;
	
	if ((chld0 = fork()) > 0) {
		// "Dispatcher" process after creating child 0
		cprintf("Created new child: 0x%x\n", chld0);
		if ((r = sys_env_set_priority(chld0, 0))) panic("Failed to set child 0's priority: %e", r);

		if ((chld1 = fork()) > 0) {
			// "Dispatcher" process after creating child 1
			cprintf("Created new child: 0x%x\n", chld1);
			if ((r = sys_env_set_priority(chld1, 1))) panic("Failed to set child 1's priority: %e", r);

			if ((chld2 = fork()) > 0) {
				// "Dispatcher" process after creating child 2
				cprintf("Created new child: 0x%x\n", chld2);
				if ((r = sys_env_set_priority(chld2, 2))) panic("Failed to set child 2's priority: %e", r);
				sys_yield();
				cprintf("env 0x%x exiting!\n", thisenv->env_id);
				exit();

			} else if (chld2 == 0) {
				// Child 2
				sys_yield();
				cprintf("env 0x%x exiting!\n", thisenv->env_id);
				exit();

			} else panic("Failed to fork child 2!");

		} else if (chld1 == 0) {
			// Child 1
			sys_yield();
			cprintf("env 0x%x exiting!\n", thisenv->env_id);
			exit();

		} else panic("Failed to fork child 1!");

	} else if (chld0 == 0) {
		// Child 0
		sys_yield();
		cprintf("env 0x%x exiting!\n", thisenv->env_id);
		exit();

	} else panic("Failed to fork child 0!");
}


```

This code creates 3 children with priority 0, 1, and 2, and gives them up immediately after they are created. Before they exit, they print out their `envids`. The expected output is child 0 exiting before child 1, which exits before child 2.

We add this file to all user files for lab 4 in `kern/Makefrag`:

```makefile
...
# Binary files for LAB4
KERN_BINFILES +=	user/idle \
			user/yield \
			user/dumbfork \
			user/stresssched \
			user/faultdie \
			user/faultregs \
			user/faultalloc \
			user/faultallocbad \
			user/faultnostack \
			user/faultbadhandler \
			user/faultevilhandler \
			user/forktree \
			user/sendpage \
			user/spin \
			user/fairness \
			user/pingpong \
			user/pingpongs \
			user/primes \
			user/nice	# Lab 4 challenge: priority scheduling
...
```

Which allows us to call `nice.c` with `make run-nice-nox`. It produces the following result:

```
qemu-system-i386 -nographic -drive file=obj/kern/kernel.img,index=0,media=disk,format=raw -serial mon:stdio -gdb tcp::26000 -D qemu.log -smp 1 
Physical memory: 131072K available, base = 640K, extended = 130432K
System supports PSE
check_page_free_list() succeeded!
check_page_alloc() succeeded!
check_page() succeeded!
check_kern_pgdir() succeeded!
check_page_free_list() succeeded!
check_page_installed_pgdir() succeeded!
SMP: CPU 0 found 1 CPU(s)
enabled interrupts: 1 2
[00000000] new env 00001000
[00001000] new env 00001001
Created new child: 0x1001
[00001000] new env 00001002
Created new child: 0x1002
[00001000] new env 00001003
Created new child: 0x1003
env 0x1001 exiting!
[00001001] exiting gracefully
[00001001] free env 00001001
env 0x1003 exiting!
[00001003] exiting gracefully
[00001003] free env 00001003
env 0x1002 exiting!
[00001002] exiting gracefully
[00001002] free env 00001002
env 0x1000 exiting!
[00001000] exiting gracefully
[00001000] free env 00001000
No runnable environments in the system!
Welcome to the JOS kernel monitor!
Type 'help' for a list of commands.
K> 
```

Which is what we expects.

This completes the lab.









